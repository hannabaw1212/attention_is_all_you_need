# Attention Is All You Need
I implemented the model from the "Attention Is All You Need" paper using the NumPy and TensorFlow libraries. This implementation is from scratch, without using any pre-built Transformer or attention blocks. I also used ChatGPT to refine the language (English) and improve the clarity of the code.

# Reference
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017, June 12). Attention is all you need. arXiv.org. https://arxiv.org/abs/1706.03762

### An excellent explanation of the "Attention Is All You Need" paper!
https://youtu.be/bCz4OMemCcA?si=USWVYd8XNn0QrrMr
